{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J048_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lbEseKtBSh",
        "colab_type": "code",
        "outputId": "56e2d021-b47a-4dc9-d9d0-29bb8e713aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2265 - acc: 0.9294 - val_loss: 0.1058 - val_acc: 0.9681\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0837 - acc: 0.9741 - val_loss: 0.0796 - val_acc: 0.9764\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0551 - acc: 0.9833 - val_loss: 0.0764 - val_acc: 0.9776\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0379 - acc: 0.9881 - val_loss: 0.0692 - val_acc: 0.9820\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0796 - val_acc: 0.9790\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0667 - val_acc: 0.9842\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0745 - val_acc: 0.9829\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0146 - acc: 0.9954 - val_loss: 0.0923 - val_acc: 0.9818\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0906 - val_acc: 0.9828\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.1102 - val_acc: 0.9790\n",
            "Test loss: 0.11021897765693134\n",
            "Test accuracy: 0.979\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxvYfLIxzax",
        "colab_type": "code",
        "outputId": "f15b781f-a903-48aa-97bf-3d16523625ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0960 - val_acc: 0.9812\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0925 - val_acc: 0.9812\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0905 - val_acc: 0.9819\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0892 - val_acc: 0.9826\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0882 - val_acc: 0.9827\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0874 - val_acc: 0.9830\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0868 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0863 - val_acc: 0.9833\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0859 - val_acc: 0.9835\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 9.7340e-04 - acc: 0.9999 - val_loss: 0.0856 - val_acc: 0.9836\n",
            "Test loss: 0.08555461080685445\n",
            "Test accuracy: 0.9836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLp74QwzATf",
        "colab_type": "text"
      },
      "source": [
        "**SGD**\n",
        "\n",
        "Test loss: 0.08664665951977013\n",
        "\n",
        "\n",
        "Test accuracy: 0.9847"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhHi5SE1x3bN",
        "colab_type": "code",
        "outputId": "3ad91750-606a-4137-f6b1-645a8490aa68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0951 - val_acc: 0.9826\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.1234 - val_acc: 0.9792\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.1106 - val_acc: 0.9830\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.1162 - val_acc: 0.9817\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.1164 - val_acc: 0.9830\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.1228 - val_acc: 0.9827\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1278 - val_acc: 0.9822\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1274 - val_acc: 0.9823\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.1236 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.1257 - val_acc: 0.9835\n",
            "Test loss: 0.1256571960544453\n",
            "Test accuracy: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39V1aMguzM5_",
        "colab_type": "text"
      },
      "source": [
        "**RMSprop**\n",
        "\n",
        "Test loss: 0.12649620679515766\n",
        "\n",
        "\n",
        "Test accuracy: 0.984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqC0OdUMyDvV",
        "colab_type": "code",
        "outputId": "f6e58f5d-890b-4041-dd5e-aea66820b345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0321 - acc: 0.9957 - val_loss: 0.1147 - val_acc: 0.9841\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.9833e-04 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9847\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.0473e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9845\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.9592e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.9189e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8915e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9847\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8716e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8558e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9848\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8430e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8323e-04 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9848\n",
            "Test loss: 0.10939152978743771\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ytjhMMtz2Gw",
        "colab_type": "text"
      },
      "source": [
        "**Adagard**\n",
        "\n",
        "Test loss: 0.10811926535155592\n",
        "\n",
        "\n",
        "Test accuracy: 0.9848"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDFsBzDyaOs",
        "colab_type": "code",
        "outputId": "b6562fa4-b60b-4482-b9e0-bd4ba18e50da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 2.8222e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9847\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 2.8000e-04 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9847\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 2.7849e-04 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7744e-04 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9849\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7661e-04 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7596e-04 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9849\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7542e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9849\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 2.7496e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.7458e-04 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7424e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9848\n",
            "Test loss: 0.11060112283745854\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKZtI_O6z8rN",
        "colab_type": "text"
      },
      "source": [
        "**Adadelta**\n",
        "\n",
        "Test loss: 0.10811314213337339\n",
        "\n",
        "\n",
        "Test accuracy: 0.985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoDsuqIyffM",
        "colab_type": "code",
        "outputId": "9ff0e846-3d83-4d86-b9c0-181db87403aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0204 - acc: 0.9950 - val_loss: 0.1277 - val_acc: 0.9819\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0124 - acc: 0.9967 - val_loss: 0.1096 - val_acc: 0.9822\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.1332 - val_acc: 0.9794\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.1251 - val_acc: 0.9788\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.1356 - val_acc: 0.9783\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.1069 - val_acc: 0.9824\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.1280 - val_acc: 0.9797\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1292 - val_acc: 0.9806\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1223 - val_acc: 0.9808\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.1180 - val_acc: 0.9800\n",
            "Test loss: 0.11803348994955981\n",
            "Test accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRQClsAd0Eet",
        "colab_type": "text"
      },
      "source": [
        "**Adam**\n",
        "\n",
        "Test loss: 0.11245599556569041\n",
        "\n",
        "\n",
        "Test accuracy: 0.9806"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NtYY-P3ylvs",
        "colab_type": "code",
        "outputId": "e5f11571-8427-4099-fb18-494f439a5a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.7820e-04 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9859\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.6932e-04 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9860\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.6890e-04 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9860\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6886e-04 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 0.9862\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6884e-04 - acc: 1.0000 - val_loss: 0.1217 - val_acc: 0.9859\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6882e-04 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9859\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9861\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9859\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9859\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9859\n",
            "Test loss: 0.12411949951003069\n",
            "Test accuracy: 0.9859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxV5bXw8d/KPCdkYAyQiChEQRAE\nAS1WrfNUtbW22pZqee2trfe23lZve22r16vttffWVm77WqUFtbXWqbYfrUOd36AMMgmIkjAlTMkJ\nGSHjWe8fz044hBM4QE52crK+n8/5ZI/nrHOUvfbzrL2fLaqKMcYY012c3wEYY4zpnyxBGGOMCcsS\nhDHGmLAsQRhjjAnLEoQxxpiwLEEYY4wJyxKEGfREpEhEVEQSItj2qyLybl/EZYzfLEGYAUVEtohI\nq4jkd1u+0jvIF/kTmTGxxxKEGYg2A9d3zojIJCDNv3D6h0haQMYcDUsQZiB6DPhyyPxXgMWhG4hI\ntogsFpEqEdkqIj8UkThvXbyIPCAi1SJSDlwaZt9HRWSniFSKyH+ISHwkgYnIn0Vkl4jUicjbInJK\nyLpUEfm5F0+diLwrIqneurNEpFREakVku4h81Vv+pojcHPIeB3Vxea2mb4rIJ8An3rIHvfeoF5EV\nInJ2yPbxIvJvIlImIg3e+tEiskBEft7tu7wgIv8Syfc2sckShBmI3gOyRGSid+D+AvB4t21+BWQD\nJwBzcQllnrfu68BlwFRgOnBtt31/D7QDJ3rbXADcTGReAsYDQ4EPgCdC1j0ATANmA7nA94CgiIz1\n9vsVUABMAVZF+HkAVwEzgRJvfpn3HrnAH4A/i0iKt+47uNbXJUAW8DVgH7AIuD4kieYD53v7m8FK\nVe1lrwHzArbgDlw/BO4DLgJeBRIABYqAeKAVKAnZ7/8Ab3rTrwO3hKy7wNs3ARgGtACpIeuvB97w\npr8KvBthrDne+2bjTsb2A6eF2e5O4Lke3uNN4OaQ+YM+33v/c48Qx97OzwU2Alf2sN0G4DPe9K3A\ni37/97aXvy/rszQD1WPA20Ax3bqXgHwgEdgasmwrMMqbHgls77au01hv350i0rksrtv2YXmtmXuB\nz+FaAsGQeJKBFKAszK6je1geqYNiE5HbgZtw31NxLYXOov7hPmsRcAMu4d4APHgcMZkYYF1MZkBS\n1a24YvUlwLPdVlcDbbiDfacxQKU3vRN3oAxd12k7rgWRr6o53itLVU/hyL4IXIlr4WTjWjMA4sXU\nDIwLs9/2HpYDNHFwAX54mG26hmT26g3fAz4PDFHVHKDOi+FIn/U4cKWInAZMBJ7vYTszSFiCMAPZ\nTbjulabQharaATwF3CsimV4f/3c4UKd4Cvi2iBSKyBDgjpB9dwKvAD8XkSwRiRORcSIyN4J4MnHJ\nJYA7qP9nyPsGgYXAf4vISK9YPEtEknF1ivNF5PMikiAieSIyxdt1FXC1iKSJyInedz5SDO1AFZAg\nInfhWhCdHgHuEZHx4kwWkTwvxgpc/eIx4BlV3R/BdzYxzBKEGbBUtUxVl/ew+lu4s+9y4F1csXWh\nt+63wMvAalwhuXsL5MtAErAe13//NDAigpAW47qrKr193+u2/nZgLe4gXAP8FIhT1W24ltB3veWr\ngNO8ff4HV0/ZjesCeoLDexn4O/CxF0szB3dB/TcuQb4C1AOPAqkh6xcBk3BJwgxyomoPDDLGOCLy\nKVxLa6zawWHQsxaEMQYAEUkEbgMeseRgIIoJQkQWisgeEfmwh/UiIr8UkU0iskZETg9Z9xUR+cR7\nfSVaMRpjHBGZCNTiutJ+4XM4pp+IWheT11RtBBar6qlh1l+C6ye+BHeTz4OqOlNEcoHluBuYFFgB\nTFPVvVEJ1BhjTFhRa0Go6tu4gltPrsQlD1XV94AcERkBXAi8qqo1XlJ4FXczlDHGmD7k541yozj4\n6ooKb1lPyw8hIvOB+QDp6enTJkyYEJ1IjTEmRq1YsaJaVQvCrRvQd1Kr6sPAwwDTp0/X5ct7uuLR\nGGNMOCKytad1fl7FVMnBd7MWest6Wm6MMaYP+ZkgXgC+7F3NdCZQ593F+jJwgYgM8e5yvcBbZowx\npg9FrYtJRP4InAPki0gF8CPcIGio6m+AF3FXMG3CDTc8z1tXIyL34O42BbhbVQ9X7DbGGBMFUUsQ\nqnr9EdYr8M0e1i3kwLAIx6ytrY2Kigqam5uP960GjJSUFAoLC0lMTPQ7FGPMADegi9RHUlFRQWZm\nJkVFRYQM3RyzVJVAIEBFRQXFxcV+h2OMGeBieqiN5uZm8vLyBkVyABAR8vLyBlWLyRgTPTGdIIBB\nkxw6Dbbva4yJnpjuYjLGGL8Eg0pbMEh7h9Le4aY7gkpbh7csGKTNW9ceDNIeZl247buWBZX2Drds\nWFYKX5w55shBHSVLEFEUCAQ477zzANi1axfx8fEUFLgbFpcuXUpSUtIR32PevHnccccdnHzyyVGN\n1RhzgKpSv7+dqsZmqhpaqWpsoarBvapDpuv2t7mDe0foQdsdzIN9OB7u1DE5liAGmry8PFatWgXA\nj3/8YzIyMrj99tsP2qbz4eBxceF7+373u99FPU5jBoumlvaDD/KNhx703XwrrR3BQ/ZPjBcKMpIp\nyExmRHYKE0ZkkhQfR0K8kBAXR2K8EO/9TYhzyw+7LE5I8PZPjIsjPs6tS4iPIyFOSIw/eFnn9l3L\n4tx2cXHR6Vq2BOGDTZs2ccUVVzB16lRWrlzJq6++yk9+8hM++OAD9u/fz3XXXcddd90FwFlnncVD\nDz3EqaeeSn5+PrfccgsvvfQSaWlp/OUvf2Ho0KE+fxtj/NXc1tF1gK9ubD30TD8kCexr7Thk/ziB\nvIxkCjKSyc9M5sShmRRkuiSQn5FEQWYyQzOTKchIISs1YVDV+QZNgvjJX9exfkd9r75nycgsfnR5\nJM+yP9RHH33E4sWLmT59OgD3338/ubm5tLe38+lPf5prr72WkpKSg/apq6tj7ty53H///XznO99h\n4cKF3HHHHeHe3pgBr6W9gz31Leyub2ZXfTO76prZ09DCrrpmdtc3U9XYQnVDC/XN7WH3H5KW6B3k\nk5k6JqfrzD/f+9s5nZueRHyUzsAHukGTIPqbcePGdSUHgD/+8Y88+uijtLe3s2PHDtavX39IgkhN\nTeXiiy8GYNq0abzzzjt9GrMxvSEYVPbua2VXvTvQ76pzSaAzEez2kkJNU+sh+yYlxDE8K4VhWclM\nHJ5FwfgDZ/kF3ll+fmYSeenJJCXE/EWaUTdoEsSxnulHS3p6etf0J598woMPPsjSpUvJycnhhhtu\nCHsvQ2hROz4+nvb28GdOxvhlf2tHyNm++9uZCHbXt3Qtb+s4uIIrAnnpyQzPTmZkdgpTx+QwPCuF\n4VkpDM1KZni2m85OTRxUXTx+GzQJoj+rr68nMzOTrKwsdu7cycsvv8xFF9kzkkz/sa+1nUBjKzVN\nrWHP9jsTQUOY7p60pHjvrD+FGcW5DPNaAMOzUhjmHfgLMpNJjLcz/v7GEkQ/cPrpp1NSUsKECRMY\nO3Ysc+bM8TskE8NUlabWDmoaWwk0tVDT1EqgyR38A40tXdNu3v3d33ZocTc+zl3RMyw7hRMK0pk1\nLo9h3ln/sKwUhmcnMywrhcwUGxdsoIraM6n7WrgHBm3YsIGJEyf6FJF/Buv3HqxUlYaWdu+A38OB\nvqmVmqYWahpbqW5qpbX90Es4AZIT4shLTyI3I4nc9GTy0pO65vPS3bLOs/+8jGQr7sYAEVmhqtPD\nrbMWhDH9WEdQ2bSnkbWVdeyq23/I2X2gqYW9TW1hr9kHSE2MJzc9ibyMJAoykjl5WBZ5GUnkprtX\nnve382qetKR46+M3XSxBGNNPqCpbAvtYU1HLmoo61lTU8mFl/UHdOxnJCV0H9xHZKZwyMqvr7D4v\nPTnkTN/NpybF+/iNzEBnCcIYH6gqO+qaWVtRy2ovGaytqOu6pj85IY5TRmZx3RmjmVyYzeTCbAqH\npJGSaAd803csQRjTB6obW1hTUcvq7XWsrXQJobrRXeefECdMGJHJpZNHclphNpMLcxg/LMOu6jG+\nswRhTC+r29/G2oo61lTWsma7SwY76tx9LSJwYkEGc08aymmjs5k0KpuJI7KsZWD6JUsQxhyHfa3t\nrNtRz+rtrm6wtrKOzdVNXevH5qUxrSiXeaNcN9Gpo7JJT7Z/dmZgsP9To6g3hvsGWLhwIZdccgnD\nhw+PWqzmyFraO/hoZ0NIEbmOT/Y0dA3rPCI7hUmjsrl2WiGTC13rICctsv/GxvRHliCiKJLhviOx\ncOFCTj/9dEsQfUhV2V6zn/c3B1jltQ4+2lXfNUREbnoSkwuzufDU4Uwelc3k0dkMzUzxOWpjeldU\nE4SIXAQ8CMQDj6jq/d3WjwUWAgVADXCDqlZ4634KXOpteo+q/imasfa1RYsWsWDBAlpbW5k9ezYP\nPfQQwWCQefPmsWrVKlSV+fPnM2zYMFatWsV1111HamrqUbU8TOSCQeWTPY0s3VLD0s01LN0cYHd9\nCwCZyQlMKszma2cVc1phDpMLsxmVk2r3C5iYF7UEISLxwALgM0AFsExEXlDV9SGbPQAsVtVFInIu\ncB9wo4hcCpwOTAGSgTdF5CVVPfbxul+6A3atPebdwxo+CS6+/8jbdfPhhx/y3HPPUVpaSkJCAvPn\nz+fJJ59k3LhxVFdXs3ati7O2tpacnBx+9atf8dBDDzFlypTejX8Qa+8Ism5HPUs31/D+5hqWb62h\ndl8bAMOykplRnMeMoiHMKM5j/NCMqD2QxZj+LJotiBnAJlUtBxCRJ4ErgdAEUQJ8x5t+A3g+ZPnb\nqtoOtIvIGuAi4KkoxttnXnvtNZYtW9Y13Pf+/fsZPXo0F154IRs3buTb3/42l156KRdccIHPkcaO\n5rYOVm2vZdnmGpZuqWHF1r1dD48pykvjgpJhnFGUy8ziPEbnWuvAGIhughgFbA+ZrwBmdttmNXA1\nrhvqs0CmiOR5y38kIj8H0oBPc3BiAUBE5gPzAcaMOcLzWI/hTD9aVJWvfe1r3HPPPYesW7NmDS+9\n9BILFizgmWee4eGHH/YhwoGvobmNFVv3et1FNaypqKO1I4gInDwsk2unFTKjOJcZRbkMzbLagTHh\n+F2kvh14SES+CrwNVAIdqvqKiJwBlAJVwBLgkOEkVfVh4GFwg/X1VdDH6/zzz+faa6/ltttuIz8/\nn0AgQFNTE6mpqaSkpPC5z32O8ePHc/PNNwOQmZlJQ0ODz1H3b4HGFpZtcd1Fy7bUsH5HPUF1N6FN\nKsxm3pwiZhTnMn1sLtlpNrqoMZGIZoKoBEaHzBd6y7qo6g5cCwIRyQCuUdVab929wL3euj8AH0cx\n1j41adIkfvSjH3H++ecTDAZJTEzkN7/5DfHx8dx0002oKiLCT3/6UwDmzZvHzTffbEXqEJW1+1m6\nOcDSzXtZujlAWZW79yAlMY6po4fwrXPHM6M4l6ljckhL8vs8yJiBKWrDfYtIAu6gfh4uMSwDvqiq\n60K2yQdqVDUoIvfiWg93eQXuHFUNiMhk4A/AFK8mEZYN931ArH1vVaWsqollXVcY1VBZux+AzJQE\nzijKZUZxLmcU5TJpVLY9atKYo+DLcN+q2i4itwIv4y5zXaiq60TkbmC5qr4AnAPcJyKK62L6prd7\nIvCOVyisx13+as/XHES2Bfbx2obdXUkh4D2fOD8jmZnFuXz97GJmFOdx8vBMeyaBMVES1ba3qr4I\nvNht2V0h008DT4fZrxl3JZMZRIJB5a1PqlhcuoU3P65CFUbnpjL35AJmFucyoziPorw0u8LImD4S\n852znf35g8VAfEJg3b42/rxiO4+9t5WtgX0UZCbzrXPH8/nphRQOSfM7PGMGrZhOECkpKQQCAfLy\n8gZFklBVAoEAKSkD47LN9TvqWbxkC8+vqqS5LcgZRUP47gUnc9Epw62OYEw/ENMJorCwkIqKCqqq\nqvwOpc+kpKRQWFjodxg9am0P8vd1u1hcuoXlW/eSkhjHZ6eO4sYziygZmeV3eMaYEDGdIBITEyku\nLvY7DAPsrm/mife38cel26hqaGFsXho/vHQin5s22u5LMKafiukEYfylqizdXMPiJVt5ed0uOlT5\n9MlDuXHWWOaOL7DxjYzp5yxBmF7X1NLO86sqeWzJVj7a1UB2aiLz5hRxw5ljGZuX7nd4xpgIWYIw\nvaa8qpHH3tvK0ysqaGhup2REFj+9ZhJXnDaK1CR7pKYxA40lCHNcOoLKGx/tYdGSLbzzSTWJ8cLF\np47gK7PHcvqYIYPi6jFjYpUlCHNM9ja18qfl23n8va1U7N3PsKxkvvOZk/jCjNH2ZDVjYoQlCHNU\n1lbUsWjJFv66egct7UFmFufyb5dM5DMlw0iMt3sXjIklliDMEbW0d/Di2p0sKt3Kqu21pCXFc+20\nQr48q4iTh2f6HV5s62iDD5+FFb+DYDtkjYLsQu/vKMgqdH/Th0KcJWjTuyxBmB7tqN3PE+9v5cml\n2wk0tXJCfjo/uryEa6YVkpVi9y5EVXMdrFgE7/8G6ish/2TIHA67P4SPX4b2/QdvH5cAmSO9pNEt\neXQmlbQ8sJqQOQqWIMxBVJUlZQEWL9nKK+t3AXDuhGF8ZfZY5ozLt3sXoq12u0sKKxZBawMUfwou\nfxBOPP/AwV0V9u+FugqXPLr+VkL9DqhcDhtegI7Wg987IQWyRh7cCskaeXCLJCXHkojpYgnCdGls\naef2p1bz93W7GJKWyPxPjeNLM8cwOtcGzIu6Haug9Few7jk3f+o1MPtWGHHaoduKQFque42YHP79\ngkHYV90teVR4fyth8zvQsBO024MaE9MP3wrJGgXJGb373U2/ZQnCALC5uon5i5dTVtXI9y+awLw5\nRaQk2r0LURUMwqbXoPSXsOUdSMqEM78BM2+BnNFH3v9w4uIgY6h7jTq9h8/vgIZdYVoh3uuTDdC4\nG+g2QnBShvfew93fzOEh88Mgc5j7m5Y/sOsiwSA010JTVcirGhr3HJiPT4STL4GTLoKU2BtLzBKE\n4Y2P9vDtJ1eSECc8ftNMZp+Y73dIsa2tGdY+BaUPQfVGd1Z+wX/A6V+GlOy+iyMu3rUOskfB6Bnh\nt2lvdS2N0FZI4x6XWBr3uJpI2evQUn/ovhIP6QUHEkbn66CE4iWYxNToftdObc0HH+ybqqBpT8h0\nFTR6f/dVuwsDDv1irp6TXuC6+tY9B/FJMO48OOUqOPnivv3vGEWWIAYxVWXBG5v4+asfM3F4Fv/3\nxmn9oztJFXaugobdMOZMSM3xO6Lesa8Glj8K7z/sDkrDJ8HVv4VTPuvORPujhCQYMta9Dqd1n2tt\ndL4aOqd3HUgoO9e4763BQ/dPzgpJIt1bJZ3zwyA19+BWSbiz/Maqbmf9IQkhXCIDSEiFjAJ3NVh2\nIYyc4j43vcB75bt16QWuay8u/sDnVyyD9c/D+r/Axy9BXCKMO/dAskgdcmy/fT8QtWdS97Vwz6Q2\nPQutN1w5ZST3Xz3Z/+EwmqphzVOw8nHY4z26XOJcP3zxXDhhLow+E5L6QRI7GjXlsOR/YdUT0LYP\nTvwMzP6WK0APtoJwsAP2BXpOIo17Dsy3Nh66f1yCO1CnZLuz98Od5afnhxzcvYN/13SBlwC8+aRe\nGCMsGITKFQeSRd12lyxOOAdKroQJl7rk0s8c7pnUliAGodB6w79dMpGbzir2b0iMjnbXRbHyMdj4\nEgTbYOTpMPUGyD8JtrwLm99yZ2nBdteUL5zhkkXxXNe/3l/PvrcvdYXnDX91MU7+PMy6FYZO9Duy\ngaGlsYdWyW53GXDqkG5n+SGv0LN8P6hC5Qdesngeare55FY810sWl0F6nn/xhbAEYbqE1hsWfPF0\n/+oNgTLXUlj9R9fHnZYHp10PU74Ew8I8jrylEba9B5vfhPK3YNdaQF3BdOwcdzZ+wlwYeoq/hdFg\nB2x80SWG7e+7y0bPuAlmzHfdJGbw6ewyXecli71bXH2m+GwouQomXu5aMj7xLUGIyEXAg0A88Iiq\n3t9t/VhgIVAA1AA3qGqFt+5nwKVAHPAqcJseJlhLEIfXL+oNLY3uH8jKx2HbEtd9NP4C11oYf6Hr\n747Uvhp35U/5W66FEdjklqfluWRR/Cl3tpZ7Qt9047Tuc11I7/2v61LKGetaC1O/1DvdFyY2qMKu\nNQeSRU25+3dQdJZrWUy8wrWK+pAvCUJE4oGPgc8AFcAy4HpVXR+yzZ+Bv6nqIhE5F5inqjeKyGzg\nv4BPeZu+C9ypqm/29HmWIHrma71B1Z1Jr3wMPnwO2pog70SXFCZ/AbJG9M7n1FXC5rddsih/Cxp2\nuOXZo12i6Gxh9PZZfOMeWPpbWPYI7K+BUdNdfWHi5f52cZj+T9VdBdaZLAKbXLIYO8dLFpf3SavT\nrwQxC/ixql7ozd8JoKr3hWyzDrhIVbeL6wSvU9Usb9+HgLMAAd4GblTVDT19niWI8HyrNzTsct1H\nKx93/+MnpsOpn4WpN8LomdE9q1d1n9mZLLa84wqa4Ias6KxfFM059itMqjbCkodg9Z/cHcsTLnWJ\nIdrfzcQmVdiz3hW31z3vLn9GYMwsdzXUxMvdXe9R4FeCuBZ38L/Zm78RmKmqt4Zs8wfgfVV9UESu\nBp4B8lU1ICIPADfjEsRDqvqDMJ8xH5gPMGbMmGlbt26NyncZqPq83tDeCp+87JLCJ6+6u3THzHKt\nhZKr/LsDNxh0zfrOFsbWUnc10dFeIaUKW/+fqy98/Hc3dMWUL8Gsb0LeuL77Pib27fnItSrWPQ9V\n3nnx6DNdy6LkCncpbi/pzwliJK6lUIxrJVwDnArk42oX13mbvgp8T1Xf6enzrAVxQJ/XG3avd/3v\nq590lx1mDIcp18OUGyD/xOh97rFqb3XjFZW/5ZJGxTJ39VRPV0h1tLt/rKW/csXGtHxXdD7jJl+L\ni2aQqNroWhbr/+K6pAAKz3AnXSVXQM6Y43r7ftvF1G37DOAjVS0UkX8FUlT1Hm/dXUCzqv6sp8+z\nBOGE1huumjKS+6JVb2iugw+fca2FyhXueu+TL3athXHnQfwAugeztQm2LnFXSG1+293Q1XmF1JhZ\n7h9o3TbIG+/GR5p8Xd/d+WtMqOpNBy6d3bXWLRs1DSZ9zg3Tcgz8ShAJuCL1eUAlrkj9RVVdF7JN\nPlCjqkERuRfoUNW7ROQ64OvARbgupr8Dv1DVv/b0eZYgDtQbyqubuPPiCb1fbwgGXX/+ysfdaKHt\nzTC0xNUVJn8+ds6mO6+Q2vy2G9QuY6jrRhp/4cAeW8jElkCZ17J43rVqb3z2mN7Gz8tcLwF+gbvM\ndaGq3isidwPLVfUFrxvqPtxoYG8D31TVFu8KqP/FXcWkwN9V9TuH+6zBniCiWm+o3Q6r/gCrHnc3\n/CRnw6RrXWth5FQryhrjt7ZmSDy2R/3ajXIxLLTeUDLC1RsKh/RCvaGtGT76m2stlL8JqOuXn3oj\nTLzMuliMiRGHSxADqKPYdNcr9QZVN4BZ/U53R3PDTldTWPtnV2fIHg1zvw9TvnjkAduMMTHFEsQA\nFVpv+OGlPdzf0N7qBj5r2OWeNNaw0/u76+DptqaD94tPdtddT73BtRqs392YQckSxAD0+oZd/OhP\n7zBS9vLghbmUpL0Dbz3lHfR3uruIG3a5IY67i0+CzBHuNWKye9BJ5nB3E07mCHdnc+bIY+7PNMbE\nDksQ/U3b/vBn+Q070Pqd1O/ZxpzmPbwj7a58/0bIvukF7mCfOdJd+taZCDoP/pkj3CiXVlQ2xkTA\nEkR/oOrGKvrHPe6BKt0lphHMGMEn+zNYv6+YrIJPcfbpk0kaMurAWX/G8KMb7M4YY47AEoTf9u+F\nv/6zu5Z57ByY+X+8M36vJZA1gvL6OOY//gGb6939DVf5+fwGY8ygYQnCT1uXwLNfd11J5/8YZt92\nSEH49Y92c9uTq0iIEx772gx7XrQxps9YgvBDRzu8/V/w9s/ccwNuesXVDEIEg+7+hv9+rZfvbzDG\nmAhZguhrtdvgma/D9vfcE9Qu+S9Izjxok8aWdr771CpeXrc7uuMpGWPMYViC6EsfPuvqDRqEqx+B\nyZ87ZJPyqkbmP7aCzdVN/PtlJXxtTpHVG4wxvrAE0RdaGuHv33fDVoyaDtc8ArnFh2zWWW9IjI/j\nsZtmMHuc1RuMMf6xBBFtO1bBMze5kRfPvh3OucM9Y6CbDyvruGnRcqs3GGP6DUsQ0RIMwnsL4LWf\nuBvYvvJXKD67x81f27AbAZ64eSY5aXY/gzHGf5YgoqFhNzx/C5S9DhMugyt+5e5gPozSsgCnjsq2\n5GCM6TcsQfS2j1+B57/hnlJ22f/AtHlHHNpif2sHK7ft5WtnHVqXMMYYv1iC6C1tzfDaj+H9X8Ow\nU+GaR2HohIh2Xb61hrYOtaK0MaZfsQTRG6o2wtM3we61MPMWOP8nRzUaamlZgIQ44YyiIVEM0hhj\njo4liOOhCit+D3+/E5LS4ItPwUkXHvXblJYFmDomh7Qk+89hjOk/7Ekwx2pfDTx1I/ztn2HMmfCN\n0mNKDvXNbaytqGWWdS8ZY/oZO2U9FlvehWfnQ+Me+Mw9MOvWY37q2tLyGoIKs8fl9XKQxhhzfKLa\nghCRi0Rko4hsEpE7wqwfKyL/EJE1IvKmiBR6yz8tIqtCXs0iclU0Y41IRxu8/h/w+8sgIQVufhXm\nfPu4HslZWhYgOSGOqWNyejFQY4w5flFrQYhIPLAA+AxQASwTkRdUdX3IZg8Ai1V1kYicC9wH3Kiq\nbwBTvPfJBTYBr0Qr1ojs3QLP3AwVy2DKDXDxTyE547jftrSsmjOKcklOsMH4jDH9SzRbEDOATapa\nrqqtwJPAld22KQFe96bfCLMe4FrgJVXdF7VIj2TNn+E3Z7urla55FK5a0CvJIdDYwke7Gphl3UvG\nmH4omgliFLA9ZL7CWxZqNXC1N/1ZIFNEuh8tvwD8MSoRHklLAzx3Czx7MxRMgFvehUnX9trbv1de\nA1j9wRjTPx0xQYjIt0QkWhfo3w7MFZGVwFygEugI+ewRwCTg5R5imy8iy0VkeVVVVe9GVrkC/u+n\nYM2f4FPfg3kvwZCxvfoRpZbDq/YAABWdSURBVGXVZCQnMGlUdq++rzHG9IZIWhDDcPWDp7yic6QP\nJ6gERofMF3rLuqjqDlW9WlWnAj/wltWGbPJ54DlVbQv3Aar6sKpOV9XpBQUFEYZ1BMEgvPsLePQC\naG+Fr/wNzv0BxPd+uWZJWYCZxbkkxNvVxsaY/ueIRyZV/SEwHngU+CrwiYj8p4iMO8Kuy4DxIlIs\nIkm4rqIXQjcQkXwR6YzhTmBht/e4nr7sXqrfCY9dBa/9CE6+BL7xLhTNicpH7azbT3l1k9UfjDH9\nVkSnrqqqwC7v1Q4MAZ4WkZ8dZp924FZc99AG4ClVXScid4vIFd5m5wAbReRjXEvl3s79RaQI1wJ5\n6+i+0jHa+BL8ejZsXwqX/xI+vxhSozf0xZKyAICNv2SM6beO2G8iIrcBXwaqgUeAf1XVNu/M/xPg\nez3tq6ovAi92W3ZXyPTTwNM97LuFQ4vava9tP7zy77DstzB8ElyzEApOivrHlpYFGJKWyIThmUfe\n2BhjfBBJx3oucLWqbg1dqKpBEbksOmH1oaYqWPMUnPlPcP6PISE56h+pqiwpCzBrXB5xcfa8aWNM\n/xRJgngJqOmcEZEsYKKqvq+qG6IWWV/JGQPfWgEZvVTkjsC2mn1U1u7nlnOOVMYxxhj/RFKD+DXQ\nGDLf6C2LHX2YHMB1L4Hd/2CM6d8iSRDiFakB17WEDfJ3XErLAgzLSuaE/HS/QzHGmB5FkiDKReTb\nIpLovW4DyqMdWKxy9YdqZo/LJ/JbSowxpu9FkiBuAWbjbnKrAGYC86MZVCz7ZE8j1Y2tdv+DMabf\nO2JXkaruwd3kZnpB6aZqwOoPxpj+L5L7IFKAm4BTgK4HLavq16IYV8wqLQswJjeNwiFpfodijDGH\nFUkX02PAcOBC3F3NhUBDNIOKVR1B5b3ygLUejDEDQiQJ4kRV/XegSVUXAZfi6hDmKK3fUU99c7vV\nH4wxA0IkCaJzJNVaETkVyAaGRi+k2FVa5uoPliCMMQNBJPczPOw9D+KHuNFYM4B/j2pUMaq0LMD4\noRkMzUw58sbGGOOzwyYIb0C+elXdC7wNnNAnUcWg1vYgy7bU8LlphX6HYowxETlsF5N313SPo7Wa\nyK2pqGVfawezbHhvY8wAEUkN4jURuV1ERotIbucr6pHFmNKyACJw5gn20xljBoZIahDXeX+/GbJM\nse6mo1JaVs0pI7PISUvyOxRjjIlIJHdSF/dFILGsua2DD7bW8tU5RX6HYowxEYvkTuovh1uuqot7\nP5zY9MHWvbR2BO3yVmPMgBJJF9MZIdMpwHnAB4AliAiVlgVIiBPOKLL6gzFm4Iiki+lbofMikgM8\nGbWIYlBpWTWTC7PJSLbHaBhjBo5IrmLqrgmwukSEGlvaWV1Rx2y7vNUYM8BEUoP4K+6qJXAJpQR4\nKpI3F5GLgAeBeOARVb2/2/qxwEKgAPfc6xtUtcJbNwZ4BBjtff4lqrolks/tT5ZtrqEjqDZAnzFm\nwImkz+OBkOl2YGvnQfxwRCQeWAB8BvegoWUi8oKqru/23otVdZGInAvcB9zorVsM3Kuqr4pIBhCM\nINZ+p7SsmqSEOE4fO8TvUIwx5qhEkiC2ATtVtRlARFJFpCiCs/kZwCZVLff2exK4EghNECXAd7zp\nN4DnvW1LgARVfRVAVRsj+zr9T2lZgGljhpCSGO93KMYYc1QiqUH8mYPP3ju8ZUcyCtgeMl/hLQu1\nGrjam/4skCkiecBJuNFjnxWRlSLyX16L5CAiMl9ElovI8qqqqghC6lt7m1pZv7PeupeMMQNSJAki\nQVVbO2e86d66Hfh2YK6IrATm4p573YFr2ZztrT8Dd9f2V7vvrKoPq+p0VZ1eUFDQSyH1nvc3B1CF\n2SdagjDGDDyRJIgqEbmic0ZErgSqI9ivEldg7lToLeuiqjtU9WpVnQr8wFtWi2ttrFLVclVtx3U9\nnR7BZ/YrpWUB0pLimVyY43coxhhz1CKpQdwCPCEiD3nzFUDYu6u7WQaMF5FiXGL4AvDF0A1EJB+o\n8UaNvRN3RVPnvjkiUqCqVcC5wPIIPrNfKS0LMKM4l8T4Y7ma2Bhj/HXEI5eqlqnqmbiCcomqzlbV\nTRHs1w7cCrwMbACeUtV1InJ3SIvkHGCjiHwMDAPu9fbtwHUv/UNE1gIC/Paov52P9tQ3s2lPo9Uf\njDEDViT3Qfwn8DOv6wfv6XLfVdUfHmlfVX0ReLHbsrtCpp8Gnu5h31eByUf6jP5qSXkAwG6QM8YM\nWJH0fVzcmRwAvKfLXRK9kGJD6aYA2amJTByR5XcoxhhzTCJJEPEiktw5IyKpQPJhtjdAaXk1Z56Q\nS3yc+B2KMcYck0gSxBO4WsBNInIz8CqwKLphDWzba/axvWa/dS8ZYwa0SEZz/amIrAbOx42J9DIw\nNtqBDWRLyjrrD1agNsYMXJFef7kblxw+h7vkdEPUIooBpWXV5Gckc+LQDL9DMcaYY9ZjC0JETgKu\n917VwJ8AUdVP91FsA5KqUloWYPa4PESs/mCMGbgO18X0EfAOcFnnfQ8i8i99EtUAVlbVxJ6GFute\nMsYMeIfrYroa2Am8ISK/FZHzcDesmcNYUuZGIbECtTFmoOsxQajq86r6BWACbijufwaGisivReSC\nvgpwoCktCzAqJ5XRual+h2KMMcclkqE2mlT1D6p6OW7AvZXA96Me2QAUDCpLyq3+YIyJDUc1ipyq\n7vWG2D4vWgENZBt21VO7r82G9zbGxAQbZrQXdd7/MOsEqz8YYwY+SxC9qLQswAkF6QzPTvE7FGOM\nOW6WIHpJW0eQ9736gzHGxAJLEL1kbWUdTa0ddnmrMSZmWILoJZ31hzNPsBaEMSY2WILoJaVl1Uwc\nkUVuepLfoRhjTK+wBNELmts6WL5lr9UfjDExxRJEL1i5rZaW9qAlCGNMTLEE0QuWlFUTHyfMKM71\nOxRjjOk1UU0QInKRiGwUkU0ickeY9WNF5B8iskZE3hSRwpB1HSKyynu9EM04j1dpWYBJo7LJTEn0\nOxRjjOk1UUsQIhIPLAAuBkqA60WkpNtmDwCLVXUycDdwX8i6/ao6xXtdEa04j1dTSzurttda95Ix\nJuZEswUxA9ikquWq2go8CVzZbZsS4HVv+o0w6/u9ZVtqaA+q3f9gjIk50UwQo4DtIfMV3rJQq3HP\nnQD4LJApIp2n4ikislxE3hORq8J9gIjM97ZZXlVV1ZuxR2xJWYCk+DimjR3iy+cbY0y0+F2kvh2Y\nKyIrgblAJdDhrRurqtOBLwK/EJFx3Xf2RpadrqrTCwoK+izoUKVlAaaOySE1Kd6XzzfGmGiJZoKo\nBEaHzBd6y7qo6g5VvVpVpwI/8JbVen8rvb/lwJvA1CjGekzq9rXx4Y46Zln9wRgTg6KZIJYB40Wk\nWESSgC8AB12NJCL5ItIZw53AQm/5EBFJ7twGmAOsj2Ksx+S9zQFU7fGixpjYFLUEoartwK3Ay8AG\n4ClVXScid4tI51VJ5wAbReRjYBhwr7d8IrBcRFbjitf3q2q/SxBLygKkJMYxZXSO36EYY0yvS4jm\nm6vqi8CL3ZbdFTL9NPB0mP1KgUnRjK03lJZVc0ZRLkkJfpdyjDGm99mR7RhVNbTw8e5G614yxsQs\nSxDHaEm5G97bbpAzxsQqSxDHaElZNZkpCZwyMsvvUIwxJiosQRyjJWUBZhbnkRBvP6ExJjbZ0e0Y\nVNbuZ0tgn3UvGWNimiWIY9D5eNHZJ1qCMMbELksQx6C0rJq89CROGprpdyjGGBM1liCOkqqypCzA\nmePyiIsTv8MxxpiosQRxlLYE9rGzrtnqD8aYmGcJ4iiVllUDNv6SMSb2WYI4SqVlAUZkp1CUl+Z3\nKMYYE1WWII5CMKi8VxZg1rg8RKz+YIyJbZYgjsLHexoINLVa95IxZlCwBHEUSje5+x/sAUHGmMHA\nEsRRKC0LUJSXxqicVL9DMcaYqLMEEaH2jiDvlweYZd1LxphBwhJEhNbtqKehpd3ufzDGDBqWICJU\n6o2/dOYJliCMMYODJYgIlZZVc/KwTAoyk/0OxRhj+oQliAi0tgdZtqXGrl4yxgwqliAisGp7Lc1t\nQas/GGMGlagmCBG5SEQ2isgmEbkjzPqxIvIPEVkjIm+KSGG39VkiUiEiD0UzziMpLasmTmCm1R+M\nMYNI1BKEiMQDC4CLgRLgehEp6bbZA8BiVZ0M3A3c1239PcDb0YoxUqVlAU4dlU12aqLfoRhjTJ+J\nZgtiBrBJVctVtRV4Eriy2zYlwOve9Buh60VkGjAMeCWKMR7R/tYOVm7ba/UHY8ygE80EMQrYHjJf\n4S0LtRq42pv+LJApInkiEgf8HLj9cB8gIvNFZLmILK+qquqlsA+2fGsNbR1q4y8ZYwYdv4vUtwNz\nRWQlMBeoBDqAfwJeVNWKw+2sqg+r6nRVnV5QUBCVAEvLAiTECWcUDYnK+xtjTH+VEMX3rgRGh8wX\nesu6qOoOvBaEiGQA16hqrYjMAs4WkX8CMoAkEWlU1UMK3dFWWhZg6pgc0pKi+VMZY0z/E80WxDJg\nvIgUi0gS8AXghdANRCTf604CuBNYCKCqX1LVMapahGtlLPYjOdQ3t7G2otbGXzLGDEpRSxCq2g7c\nCrwMbACeUtV1InK3iFzhbXYOsFFEPsYVpO+NVjzHYml5DUHF7n8wxgxKUe03UdUXgRe7LbsrZPpp\n4OkjvMfvgd9HIbwjKi0LkJwQx9QxOX58vDHG+MrvInW/VlpWzRlFuSQnxPsdijHG9DlLED0INLbw\n0a4Gu//BGDNoWYLowXvlNYA9XtQYM3hZguhBaVk1GckJTB6V7XcoxhjjC0sQPVhSFmBGcS4J8fYT\nGWMGJzv6hbGzbj/l1U12easxZlCzBBHGEu/xolZ/MMYMZpYgwigtC5CTlsjE4Vl+h2KMMb6xBNGN\nqrKkLMCsE/KIixO/wzHGGN9YguhmW80+Kmv3W/3BGDPoWYLoprSr/mAD9BljBjdLEN2UlgUYmpnM\nuIJ0v0MxxhhfWYII4eoP1cwel4eI1R+MMYObJYgQn+xppLqx1R4vaowxWII4SOmmasDufzDGGLAE\ncZDSsgCjc1MZnZvmdyjGGOM7SxCejqDyXnmA2SdY95IxxoAliC7rd9RT39zO7BOte8kYY8ASRJfS\nMq/+cIIlCGOMAUsQXZaUBzhxaAZDs1L8DsUYY/qFqCYIEblIRDaKyCYRuSPM+rEi8g8RWSMib4pI\nYcjyD0RklYisE5FbohlnW0eQpZtrbHgNY4wJEbUEISLxwALgYqAEuF5ESrpt9gCwWFUnA3cD93nL\ndwKzVHUKMBO4Q0RGRivWNRW17GvtsARhjDEhotmCmAFsUtVyVW0FngSu7LZNCfC6N/1G53pVbVXV\nFm95cpTjpHRTABGYWWwJwhhjOkXzwDsK2B4yX+EtC7UauNqb/iyQKSJ5ACIyWkTWeO/xU1Xd0f0D\nRGS+iCwXkeVVVVXHHGhpWYCSEVkMSU865vcwxphY43eR+nZgroisBOYClUAHgKpu97qeTgS+IiLD\nuu+sqg+r6nRVnV5QUHBMATS3dbBi217rXjLGmG6imSAqgdEh84Xesi6qukNVr1bVqcAPvGW13bcB\nPgTOjkaQ9c1tXHTKcD49YWg03t4YYwasaCaIZcB4ESkWkSTgC8ALoRuISL6IdMZwJ7DQW14oIqne\n9BDgLGBjNIIcmpnCL6+fagP0GWNMN1FLEKraDtwKvAxsAJ5S1XUicreIXOFtdg6wUUQ+BoYB93rL\nJwLvi8hq4C3gAVVdG61YjTHGHEpU1e8YesX06dN1+fLlfodhjDEDioisUNXp4db5XaQ2xhjTT1mC\nMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwxhgTVsxc5ioiVcDW43iLfKC6l8IZ6Oy3OJj9Hgez\n3+OAWPgtxqpq2LGKYiZBHC8RWd7TtcCDjf0WB7Pf42D2exwQ67+FdTEZY4wJyxKEMcaYsCxBHPCw\n3wH0I/ZbHMx+j4PZ73FATP8WVoMwxhgTlrUgjDHGhGUJwhhjTFiDPkGIyEUislFENonIHX7H4yfv\nOeBviMh6EVknIrf5HZPfRCReRFaKyN/8jsVvIpIjIk+LyEciskFEZvkdk59E5F+8fycfisgfRSTF\n75h626BOECISDywALgZKgOtFpMTfqHzVDnxXVUuAM4FvDvLfA+A23AOvDDwI/F1VJwCnMYh/FxEZ\nBXwbmK6qpwLxuKdmxpRBnSCAGcAmVS1X1VbgSeBKn2PyjaruVNUPvOkG3AFglL9R+UdECoFLgUf8\njsVvIpINfAp4FEBVW7s/P34QSgBSRSQBSAN2+BxPrxvsCWIUsD1kvoJBfEAMJSJFwFTgfX8j8dUv\ngO8BQb8D6QeKgSrgd16X2yMiku53UH5R1UrgAWAbsBOoU9VX/I2q9w32BGHCEJEM4Bngn1W13u94\n/CAilwF7VHWF37H0EwnA6cCvVXUq0AQM2pqdiAzB9TYUAyOBdBG5wd+oet9gTxCVwOiQ+UJv2aAl\nIom45PCEqj7rdzw+mgNcISJbcF2P54rI4/6G5KsKoEJVO1uUT+MSxmB1PrBZVatUtQ14Fpjtc0y9\nbrAniGXAeBEpFpEkXJHpBZ9j8o2ICK6PeYOq/rff8fhJVe9U1UJVLcL9f/G6qsbcGWKkVHUXsF1E\nTvYWnQes9zEkv20DzhSRNO/fzXnEYNE+we8A/KSq7SJyK/Ay7iqEhaq6zuew/DQHuBFYKyKrvGX/\npqov+hiT6T++BTzhnUyVA/N8jsc3qvq+iDwNfIC7+m8lMTjshg21YYwxJqzB3sVkjDGmB5YgjDHG\nhGUJwhhjTFiWIIwxxoRlCcIYY0xYliCMOQoi0iEiq0JevXY3sYgUiciHvfV+xhyvQX0fhDHHYL+q\nTvE7CGP6grUgjOkFIrJFRH4mImtFZKmInOgtLxKR10VkjYj8Q0TGeMuHichzIrLae3UO0xAvIr/1\nnjPwioik+valzKBnCcKYo5ParYvpupB1dao6CXgINxIswK+ARao6GXgC+KW3/JfAW6p6Gm5Mo847\n+McDC1T1FKAWuCbK38eYHtmd1MYcBRFpVNWMMMu3AOeqark34OEuVc0TkWpghKq2ect3qmq+iFQB\nharaEvIeRcCrqjrem/8+kKiq/xH9b2bMoawFYUzv0R6mj0ZLyHQHVic0PrIEYUzvuS7k7xJvupQD\nj6L8EvCON/0P4BvQ9dzr7L4K0phI2dmJMUcnNWSkW3DPaO681HWIiKzBtQKu95Z9C/cUtn/FPZGt\ncwTU24CHReQmXEvhG7gnkxnTb1gNwphe4NUgpqtqtd+xGNNbrIvJGGNMWNaCMMYYE5a1IIwxxoRl\nCcIYY0xYliCMMcaEZQnCGGNMWJYgjDHGhPX/ATRPq1LHQuz4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139740784532560 -->\n<g class=\"node\" id=\"node1\">\n<title>139740784532560</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 139742319452056 -->\n<g class=\"node\" id=\"node2\">\n<title>139742319452056</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 139740784532560&#45;&gt;139742319452056 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139740784532560-&gt;139742319452056</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139740784530768 -->\n<g class=\"node\" id=\"node3\">\n<title>139740784530768</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 139742319452056&#45;&gt;139740784530768 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139742319452056-&gt;139740784530768</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139740771516032 -->\n<g class=\"node\" id=\"node4\">\n<title>139740771516032</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 139740784530768&#45;&gt;139740771516032 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139740784530768-&gt;139740771516032</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXWJYUxK0JBN",
        "colab_type": "text"
      },
      "source": [
        "**Adamax**\n",
        "\n",
        "Test loss: 0.11826916954151595\n",
        "\n",
        "\n",
        "Test accuracy: 0.9851"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN-m8uTByrY0",
        "colab_type": "code",
        "outputId": "a4c448a9-41c1-4199-975f-f5a05566c179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0404 - acc: 0.9926 - val_loss: 0.1570 - val_acc: 0.9738\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0254 - acc: 0.9936 - val_loss: 0.1371 - val_acc: 0.9786\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0213 - acc: 0.9941 - val_loss: 0.1229 - val_acc: 0.9800\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0244 - acc: 0.9931 - val_loss: 0.1292 - val_acc: 0.9788\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0163 - acc: 0.9956 - val_loss: 0.1072 - val_acc: 0.9813\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.1141 - val_acc: 0.9816\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0167 - acc: 0.9954 - val_loss: 0.1053 - val_acc: 0.9837\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0166 - acc: 0.9955 - val_loss: 0.1235 - val_acc: 0.9805\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0182 - acc: 0.9949 - val_loss: 0.1306 - val_acc: 0.9789\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.1257 - val_acc: 0.9812\n",
            "Test loss: 0.12567226941206336\n",
            "Test accuracy: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hog5uwzZ0V1F",
        "colab_type": "text"
      },
      "source": [
        "**Nadam**\n",
        "\n",
        "Test loss: 0.12597350687139072\n",
        "\n",
        "\n",
        "Test accuracy: 0.9813"
      ]
    }
  ]
}